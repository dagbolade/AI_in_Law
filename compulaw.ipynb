{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## load and clean data",
   "id": "e396d705824fbf65"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-03T12:46:25.779051Z",
     "start_time": "2025-08-03T12:46:24.605493Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel('scn_appeal_cases_data.xlsx')\n",
    "\n",
    "print(\"=== RAW DATA OVERVIEW ===\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "# Check first few rows\n",
    "print(\"\\n=== FIRST 5 ROWS ===\")\n",
    "print(df.head())\n",
    "\n",
    "# Check data types\n",
    "print(\"\\n=== DATA TYPES ===\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Check missing values\n",
    "print(\"\\n=== MISSING VALUES ===\")\n",
    "missing_info = df.isnull().sum()\n",
    "print(missing_info)\n",
    "\n",
    "# Check for 'Missing' as a string value\n",
    "print(\"\\n=== 'Missing' STRING VALUES ===\")\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        missing_count = (df[col] == 'Missing').sum()\n",
    "        if missing_count > 0:\n",
    "            print(f\"{col}: {missing_count} 'Missing' values\")\n",
    "\n",
    "# Check for negative values in numeric columns\n",
    "print(\"\\n=== NEGATIVE VALUES CHECK ===\")\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "for col in numeric_cols:\n",
    "    negative_count = (df[col] < 0).sum()\n",
    "    if negative_count > 0:\n",
    "        print(f\"{col}: {negative_count} negative values\")\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RAW DATA OVERVIEW ===\n",
      "Dataset shape: (4696, 14)\n",
      "Columns: ['appeal_district', 'trial_district', 'offence', 'sentence', 'no_complainant', 'no_male_complainant', 'no_female_complainant', 'no_appealant', 'no_male_appealant', 'no_female_appealant', 'no_public_witness', 'no_eye_witness', 'no_defense_witness', 'scn_decision']\n",
      "\n",
      "=== FIRST 5 ROWS ===\n",
      "  appeal_district trial_district              offence          sentence  \\\n",
      "0      North-West     North-West    Rape_sexual_abuse       Prison_term   \n",
      "1      South-East     South-East        Armed_robbery             Death   \n",
      "2     South-South    South-South      Damage_property  Prison_term_fine   \n",
      "3     South-South    South-South  Murder_manslaughter             Death   \n",
      "4      South-East        Missing              Missing   Payment_damages   \n",
      "\n",
      "   no_complainant  no_male_complainant  no_female_complainant  no_appealant  \\\n",
      "0               1                    0                      1             1   \n",
      "1               1                    1                      0             1   \n",
      "2               1                    1                      0            10   \n",
      "3               2                    0                      2             1   \n",
      "4               1                    1                      0             2   \n",
      "\n",
      "   no_male_appealant  no_female_appealant  no_public_witness  no_eye_witness  \\\n",
      "0                  1                    0                  4               1   \n",
      "1                  1                    0                  2               1   \n",
      "2                 10                    0                  4               0   \n",
      "3                  1                    0                  2               0   \n",
      "4                  1                    0                 -1               0   \n",
      "\n",
      "   no_defense_witness scn_decision  \n",
      "0                   0    Dismissed  \n",
      "1                   0    Dismissed  \n",
      "2                   0    Dismissed  \n",
      "3                   0    Dismissed  \n",
      "4                   0    Dismissed  \n",
      "\n",
      "=== DATA TYPES ===\n",
      "appeal_district          object\n",
      "trial_district           object\n",
      "offence                  object\n",
      "sentence                 object\n",
      "no_complainant            int64\n",
      "no_male_complainant       int64\n",
      "no_female_complainant     int64\n",
      "no_appealant              int64\n",
      "no_male_appealant         int64\n",
      "no_female_appealant       int64\n",
      "no_public_witness         int64\n",
      "no_eye_witness            int64\n",
      "no_defense_witness        int64\n",
      "scn_decision             object\n",
      "dtype: object\n",
      "\n",
      "=== MISSING VALUES ===\n",
      "appeal_district          0\n",
      "trial_district           0\n",
      "offence                  0\n",
      "sentence                 0\n",
      "no_complainant           0\n",
      "no_male_complainant      0\n",
      "no_female_complainant    0\n",
      "no_appealant             0\n",
      "no_male_appealant        0\n",
      "no_female_appealant      0\n",
      "no_public_witness        0\n",
      "no_eye_witness           0\n",
      "no_defense_witness       0\n",
      "scn_decision             0\n",
      "dtype: int64\n",
      "\n",
      "=== 'Missing' STRING VALUES ===\n",
      "appeal_district: 2742 'Missing' values\n",
      "trial_district: 1761 'Missing' values\n",
      "offence: 578 'Missing' values\n",
      "sentence: 2018 'Missing' values\n",
      "\n",
      "=== NEGATIVE VALUES CHECK ===\n",
      "no_complainant: 2131 negative values\n",
      "no_male_complainant: 3371 negative values\n",
      "no_female_complainant: 3445 negative values\n",
      "no_appealant: 1158 negative values\n",
      "no_male_appealant: 2672 negative values\n",
      "no_female_appealant: 3083 negative values\n",
      "no_public_witness: 1680 negative values\n",
      "no_eye_witness: 1711 negative values\n",
      "no_defense_witness: 1724 negative values\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Clean the data",
   "id": "59c38e6f06373308"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T12:46:38.062125Z",
     "start_time": "2025-08-03T12:46:37.999905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n=== STARTING DATA CLEANING ===\")\n",
    "print(f\"Original dataset: {len(df)} cases\")\n",
    "\n",
    "# Create a copy for cleaning\n",
    "df_clean = df.copy()\n",
    "\n",
    "# 1. Replace 'Missing' strings with NaN\n",
    "df_clean = df_clean.replace('Missing', np.nan)\n",
    "\n",
    "# 2. Fix negative values in witness/people count columns\n",
    "witness_columns = [\n",
    "    'no_complainant', 'no_male_complainant', 'no_female_complainant',\n",
    "    'no_appealant', 'no_male_appealant', 'no_female_appealant', \n",
    "    'no_public_witness', 'no_eye_witness', 'no_defense_witness'\n",
    "]\n",
    "\n",
    "print(\"\\nFixing negative values in witness columns...\")\n",
    "for col in witness_columns:\n",
    "    negative_count = (df_clean[col] < 0).sum()\n",
    "    if negative_count > 0:\n",
    "        print(f\"  {col}: Converting {negative_count} negative values to 0\")\n",
    "        df_clean[col] = df_clean[col].apply(lambda x: max(0, x) if pd.notna(x) else 0)\n",
    "\n",
    "# 3. Check missing values after initial cleaning\n",
    "print(\"\\n=== MISSING VALUES AFTER CLEANING ===\")\n",
    "missing_after = df_clean.isnull().sum()\n",
    "for col, missing_count in missing_after.items():\n",
    "    if missing_count > 0:\n",
    "        percentage = (missing_count / len(df_clean)) * 100\n",
    "        print(f\"{col}: {missing_count} missing ({percentage:.1f}%)\")\n",
    "\n",
    "# 4. Create model-ready dataset (remove cases with missing critical data)\n",
    "critical_columns = ['appeal_district', 'offence', 'scn_decision']\n",
    "print(f\"\\n=== FILTERING FOR CRITICAL COLUMNS ===\")\n",
    "print(f\"Critical columns for modeling: {critical_columns}\")\n",
    "\n",
    "df_model_ready = df_clean.dropna(subset=critical_columns)\n",
    "\n",
    "print(f\"Cases after removing missing critical data: {len(df_model_ready)}\")\n",
    "print(f\"Removed: {len(df_clean) - len(df_model_ready)} cases\")\n",
    "\n",
    "# 5. Final data quality check\n",
    "print(\"\\n=== FINAL DATA QUALITY CHECK ===\")\n",
    "print(f\"Final dataset shape: {df_model_ready.shape}\")\n",
    "\n",
    "# Check outcome distribution\n",
    "print(\"\\nOutcome distribution:\")\n",
    "outcome_counts = df_model_ready['scn_decision'].value_counts()\n",
    "for outcome, count in outcome_counts.items():\n",
    "    percentage = (count / len(df_model_ready)) * 100\n",
    "    print(f\"  {outcome}: {count} cases ({percentage:.1f}%)\")\n",
    "\n",
    "# Check regions\n",
    "print(\"\\nRegions available:\")\n",
    "regions = df_model_ready['appeal_district'].value_counts()\n",
    "for region, count in regions.items():\n",
    "    percentage = (count / len(df_model_ready)) * 100\n",
    "    print(f\"  {region}: {count} cases ({percentage:.1f}%)\")\n",
    "\n",
    "# Check offense types\n",
    "print(f\"\\nNumber of offense types: {df_model_ready['offence'].nunique()}\")\n",
    "print(\"Top 10 offense types:\")\n",
    "top_offenses = df_model_ready['offence'].value_counts().head(10)\n",
    "for offense, count in top_offenses.items():\n",
    "    print(f\"  {offense}: {count} cases\")"
   ],
   "id": "b29b095c9c394534",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STARTING DATA CLEANING ===\n",
      "Original dataset: 4696 cases\n",
      "\n",
      "Fixing negative values in witness columns...\n",
      "  no_complainant: Converting 2131 negative values to 0\n",
      "  no_male_complainant: Converting 3371 negative values to 0\n",
      "  no_female_complainant: Converting 3445 negative values to 0\n",
      "  no_appealant: Converting 1158 negative values to 0\n",
      "  no_male_appealant: Converting 2672 negative values to 0\n",
      "  no_female_appealant: Converting 3083 negative values to 0\n",
      "  no_public_witness: Converting 1680 negative values to 0\n",
      "  no_eye_witness: Converting 1711 negative values to 0\n",
      "  no_defense_witness: Converting 1724 negative values to 0\n",
      "\n",
      "=== MISSING VALUES AFTER CLEANING ===\n",
      "appeal_district: 2742 missing (58.4%)\n",
      "trial_district: 1761 missing (37.5%)\n",
      "offence: 578 missing (12.3%)\n",
      "sentence: 2018 missing (43.0%)\n",
      "\n",
      "=== FILTERING FOR CRITICAL COLUMNS ===\n",
      "Critical columns for modeling: ['appeal_district', 'offence', 'scn_decision']\n",
      "Cases after removing missing critical data: 1718\n",
      "Removed: 2978 cases\n",
      "\n",
      "=== FINAL DATA QUALITY CHECK ===\n",
      "Final dataset shape: (1718, 14)\n",
      "\n",
      "Outcome distribution:\n",
      "  Dismissed: 1211 cases (70.5%)\n",
      "  Granted: 507 cases (29.5%)\n",
      "\n",
      "Regions available:\n",
      "  South-West: 670 cases (39.0%)\n",
      "  South-South: 408 cases (23.7%)\n",
      "  South-East: 232 cases (13.5%)\n",
      "  North-West: 157 cases (9.1%)\n",
      "  FCT: 140 cases (8.1%)\n",
      "  North-Central: 100 cases (5.8%)\n",
      "  North-East: 11 cases (0.6%)\n",
      "\n",
      "Number of offense types: 21\n",
      "Top 10 offense types:\n",
      "  Dispute: 495 cases\n",
      "  Murder_manslaughter: 225 cases\n",
      "  Others: 152 cases\n",
      "  Armed_robbery: 122 cases\n",
      "  Theft: 111 cases\n",
      "  Trespassing: 93 cases\n",
      "  Civil_petition: 87 cases\n",
      "  Law_of_tort: 63 cases\n",
      "  Election_petition: 62 cases\n",
      "  Unlawful_possession: 60 cases\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## save cleaned data",
   "id": "babdbccfc0792fa9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T12:48:04.926848Z",
     "start_time": "2025-08-03T12:48:04.895686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the cleaned dataset\n",
    "df_model_ready.to_csv('cleaned_supreme_court_data.csv', index=False)\n",
    "print(f\"\\n✅ Cleaned data saved to 'cleaned_supreme_court_data.csv'\")\n",
    "print(f\"✅ Ready for modeling with {len(df_model_ready)} clean cases\")\n",
    "\n",
    "# Quick summary\n",
    "print(\"\\n=== CLEANING SUMMARY ===\")\n",
    "print(f\"Original cases: {len(df)}\")\n",
    "print(f\"After cleaning: {len(df_model_ready)}\")\n",
    "print(f\"Success rate: {(df_model_ready['scn_decision'] == 'Granted').mean():.1%}\")\n",
    "print(f\"Data quality: {len(df_model_ready)/len(df):.1%} of original data retained\")"
   ],
   "id": "7cbdd9f937832b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Cleaned data saved to 'cleaned_supreme_court_data.csv'\n",
      "✅ Ready for modeling with 1718 clean cases\n",
      "\n",
      "=== CLEANING SUMMARY ===\n",
      "Original cases: 4696\n",
      "After cleaning: 1718\n",
      "Success rate: 29.5%\n",
      "Data quality: 36.6% of original data retained\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## GENERATE KEY INSIGHTS FOR COMPULAW AI",
   "id": "acd55eab4865a788"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T12:54:13.028924Z",
     "start_time": "2025-08-03T12:54:13.009617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_clean = pd.read_csv('cleaned_supreme_court_data.csv')\n",
    "\n",
    "print(\"=== COMPULAW AI: LEGAL INTELLIGENCE INSIGHTS ===\")\n",
    "print(f\"Analyzing {len(df_clean)} clean Supreme Court cases\")\n",
    "\n",
    "# =====================================================\n",
    "# INSIGHT 1: SUCCESS RATES BY OFFENSE TYPE\n",
    "# =====================================================\n",
    "\n",
    "print(\"\\n🏆 1. BEST PERFORMING OFFENSE TYPES (50+ cases):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calculate success rates by offense\n",
    "offense_analysis = df_clean.groupby('offence').agg({\n",
    "    'scn_decision': ['count', lambda x: (x == 'Granted').sum()]\n",
    "}).round(1)\n",
    "\n",
    "# Flatten column names\n",
    "offense_analysis.columns = ['total_cases', 'granted_cases']\n",
    "offense_analysis['success_rate'] = (offense_analysis['granted_cases'] / offense_analysis['total_cases'] * 100).round(1)\n",
    "\n",
    "# Filter for meaningful sample sizes and sort by success rate\n",
    "significant_offenses = offense_analysis[offense_analysis['total_cases'] >= 50].sort_values('success_rate', ascending=False)\n",
    "\n",
    "print(\"Offense Type                          | Success Rate | Total Cases\")\n",
    "print(\"-\" * 65)\n",
    "for offense, data in significant_offenses.head(10).iterrows():\n",
    "    print(f\"{offense:35} | {data['success_rate']}% | {data['total_cases']}\")"
   ],
   "id": "fb3f41d7d15b7e5f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPULAW AI: LEGAL INTELLIGENCE INSIGHTS ===\n",
      "Analyzing 1718 clean Supreme Court cases\n",
      "\n",
      "🏆 1. BEST PERFORMING OFFENSE TYPES (50+ cases):\n",
      "============================================================\n",
      "Offense Type                          | Success Rate | Total Cases\n",
      "-----------------------------------------------------------------\n",
      "Trespassing                         | 38.7% | 93.0\n",
      "Theft                               | 37.8% | 111.0\n",
      "Others                              | 32.2% | 152.0\n",
      "Civil_petition                      | 32.2% | 87.0\n",
      "Election_petition                   | 30.6% | 62.0\n",
      "Unlawful_possession                 | 28.3% | 60.0\n",
      "Murder_manslaughter                 | 28.0% | 225.0\n",
      "Dispute                             | 27.5% | 495.0\n",
      "Law_of_tort                         | 27.0% | 63.0\n",
      "Armed_robbery                       | 24.6% | 122.0\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T13:11:48.866087Z",
     "start_time": "2025-08-03T13:11:48.853821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"\\n🗺️  2. REGIONAL SUCCESS PATTERNS:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calculate success rates by region\n",
    "regional_analysis = df_clean.groupby('appeal_district').agg({\n",
    "    'scn_decision': ['count', lambda x: (x == 'Granted').sum()]\n",
    "}).round(1)\n",
    "\n",
    "regional_analysis.columns = ['total_cases', 'granted_cases']\n",
    "regional_analysis['success_rate'] = (regional_analysis['granted_cases'] / regional_analysis['total_cases'] * 100).round(1)\n",
    "\n",
    "# Sort by success rate\n",
    "regional_sorted = regional_analysis.sort_values('success_rate', ascending=False)\n",
    "\n",
    "print(\"Region                | Success Rate | Total Cases\")\n",
    "print(\"-\" * 45)\n",
    "for region, data in regional_sorted.iterrows():\n",
    "    print(f\"{region[:18]:<18} | {data['success_rate']:>8}%   | {data['total_cases']:>9}\")"
   ],
   "id": "68db240911ac0575",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🗺️  2. REGIONAL SUCCESS PATTERNS:\n",
      "==================================================\n",
      "Region                | Success Rate | Total Cases\n",
      "---------------------------------------------\n",
      "North-East         |     45.5%   |      11.0\n",
      "South-South        |     32.8%   |     408.0\n",
      "North-Central      |     32.0%   |     100.0\n",
      "South-West         |     30.9%   |     670.0\n",
      "South-East         |     27.6%   |     232.0\n",
      "North-West         |     24.2%   |     157.0\n",
      "FCT                |     19.3%   |     140.0\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T13:12:29.197303Z",
     "start_time": "2025-08-03T13:12:29.180278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"\\n👁️  3. WITNESS IMPACT ON SUCCESS RATES:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Eye witness impact (cases with 20+ occurrences)\n",
    "eye_witness_analysis = df_clean.groupby('no_eye_witness').agg({\n",
    "    'scn_decision': ['count', lambda x: (x == 'Granted').sum()]\n",
    "}).round(1)\n",
    "\n",
    "eye_witness_analysis.columns = ['total_cases', 'granted_cases']\n",
    "eye_witness_analysis['success_rate'] = (eye_witness_analysis['granted_cases'] / eye_witness_analysis['total_cases'] * 100).round(1)\n",
    "\n",
    "# Filter for meaningful sample sizes\n",
    "significant_witness_counts = eye_witness_analysis[eye_witness_analysis['total_cases'] >= 20].sort_index()\n",
    "\n",
    "print(\"Eye Witnesses | Success Rate | Total Cases\")\n",
    "print(\"-\" * 40)\n",
    "for witnesses, data in significant_witness_counts.iterrows():\n",
    "    print(f\"{witnesses:>11}   | {data['success_rate']:>8}%   | {data['total_cases']:>9}\")\n",
    "\n"
   ],
   "id": "1a5575ebe841929c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "👁️  3. WITNESS IMPACT ON SUCCESS RATES:\n",
      "==================================================\n",
      "Eye Witnesses | Success Rate | Total Cases\n",
      "----------------------------------------\n",
      "          0   |     29.8%   |    1662.0\n",
      "          1   |     20.8%   |      24.0\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T13:13:12.140274Z",
     "start_time": "2025-08-03T13:13:12.128135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"\\n⚖️  4. SUCCESS RATES BY SENTENCE TYPE:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Analyze success by sentence type (excluding missing data)\n",
    "sentence_data = df_clean[df_clean['sentence'].notna()]\n",
    "\n",
    "sentence_analysis = sentence_data.groupby('sentence').agg({\n",
    "    'scn_decision': ['count', lambda x: (x == 'Granted').sum()]\n",
    "}).round(1)\n",
    "\n",
    "sentence_analysis.columns = ['total_cases', 'granted_cases']\n",
    "sentence_analysis['success_rate'] = (sentence_analysis['granted_cases'] / sentence_analysis['total_cases'] * 100).round(1)\n",
    "\n",
    "# Filter for meaningful sample sizes\n",
    "significant_sentences = sentence_analysis[sentence_analysis['total_cases'] >= 20].sort_values('success_rate', ascending=False)\n",
    "\n",
    "print(\"Sentence Type              | Success Rate | Total Cases\")\n",
    "print(\"-\" * 55)\n",
    "for sentence, data in significant_sentences.head(8).iterrows():\n",
    "    print(f\"{sentence[:25]:<25} | {data['success_rate']:>8}%   | {data['total_cases']:>9}\")\n",
    "\n"
   ],
   "id": "69043d5ae9f1f8a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚖️  4. SUCCESS RATES BY SENTENCE TYPE:\n",
      "==================================================\n",
      "Sentence Type              | Success Rate | Total Cases\n",
      "-------------------------------------------------------\n",
      "Appeal_granted            |     45.3%   |     137.0\n",
      "Others                    |     42.4%   |      33.0\n",
      "Fine                      |     33.6%   |     107.0\n",
      "Appeal_dismissed          |     30.2%   |      63.0\n",
      "Prison_term               |     29.1%   |     148.0\n",
      "Payment_damages           |     24.6%   |     272.0\n",
      "Death                     |     24.1%   |     266.0\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T13:14:25.447467Z",
     "start_time": "2025-08-03T13:14:25.437419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"\\n🧠 5. KEY PATTERNS FOR COMPULAW AI:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Best offense types for appeals\n",
    "best_offense = significant_offenses.head(1)\n",
    "worst_offense = significant_offenses.tail(1)\n",
    "\n",
    "best_region = regional_sorted.head(1)\n",
    "worst_region = regional_sorted.tail(1)\n",
    "\n",
    "print(f\"✅ HIGHEST SUCCESS RATE:\")\n",
    "for offense, data in best_offense.iterrows():\n",
    "    print(f\"   Offense: {offense} ({data['success_rate']}% success)\")\n",
    "for region, data in best_region.iterrows():\n",
    "    print(f\"   Region: {region} ({data['success_rate']}% success)\")\n",
    "\n",
    "print(f\"\\n❌ LOWEST SUCCESS RATE:\")\n",
    "for offense, data in worst_offense.iterrows():\n",
    "    print(f\"   Offense: {offense} ({data['success_rate']}% success)\")\n",
    "for region, data in worst_region.iterrows():\n",
    "    print(f\"   Region: {region} ({data['success_rate']}% success)\")\n",
    "\n",
    "# Witness pattern\n",
    "eye_witness_pattern = significant_witness_counts['success_rate']\n",
    "if len(eye_witness_pattern) > 1:\n",
    "    witness_trend = \"increases\" if eye_witness_pattern.iloc[-1] > eye_witness_pattern.iloc[0] else \"decreases\"\n",
    "    print(f\"\\n👁️  WITNESS PATTERN: Success rate generally {witness_trend} with more eye witnesses\")\n",
    "\n",
    "# Overall insight\n",
    "total_cases = len(df_clean)\n",
    "total_granted = (df_clean['scn_decision'] == 'Granted').sum()\n",
    "overall_success = (total_granted / total_cases * 100)\n",
    "\n",
    "print(f\"\\n📊 OVERALL BASELINE:\")\n",
    "print(f\"   Total Cases Analyzed: {total_cases:,}\")\n",
    "print(f\"   Overall Success Rate: {overall_success:.1f}%\")\n",
    "print(f\"   Cases Granted: {total_granted:,}\")\n",
    "print(f\"   Cases Dismissed: {total_cases - total_granted:,}\")\n",
    "\n",
    "print(f\"\\n✅ INSIGHTS GENERATION COMPLETE!\")\n",
    "print(f\"Ready for Step 3: Building the prediction model\")"
   ],
   "id": "2b924b78ec9eebee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 5. KEY PATTERNS FOR COMPULAW AI:\n",
      "==================================================\n",
      "✅ HIGHEST SUCCESS RATE:\n",
      "   Offense: Trespassing (38.7% success)\n",
      "   Region: North-East (45.5% success)\n",
      "\n",
      "❌ LOWEST SUCCESS RATE:\n",
      "   Offense: Armed_robbery (24.6% success)\n",
      "   Region: FCT (19.3% success)\n",
      "\n",
      "👁️  WITNESS PATTERN: Success rate generally decreases with more eye witnesses\n",
      "\n",
      "📊 OVERALL BASELINE:\n",
      "   Total Cases Analyzed: 1,718\n",
      "   Overall Success Rate: 29.5%\n",
      "   Cases Granted: 507\n",
      "   Cases Dismissed: 1,211\n",
      "\n",
      "✅ INSIGHTS GENERATION COMPLETE!\n",
      "Ready for Step 3: Building the prediction model\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## BUILD THE PREDICTION MODEL",
   "id": "bed550fbc800204c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T13:17:24.124288Z",
     "start_time": "2025-08-03T13:17:17.658394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"=== STEP 3: BUILDING COMPULAW AI PREDICTION MODEL ===\")\n",
    "\n",
    "# Load cleaned data\n",
    "df_clean = pd.read_csv('cleaned_supreme_court_data.csv')\n",
    "print(f\"Building model with {len(df_clean)} cases\")"
   ],
   "id": "de4161b9d8f63ed3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 3: BUILDING COMPULAW AI PREDICTION MODEL ===\n",
      "Building model with 1718 cases\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T12:34:16.275740Z",
     "start_time": "2025-08-10T12:34:15.941175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n1. PREPARING DATA FOR ML...\")\n",
    "\n",
    "# Create label encoders for categorical variables\n",
    "encoders = {}\n",
    "df_ml = df_clean.copy()\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['offence', 'appeal_district', 'trial_district', 'sentence']\n",
    "\n",
    "for feature in categorical_features:\n",
    "    # Handle missing values first\n",
    "    df_ml[feature] = df_ml[feature].fillna('Unknown')\n",
    "    \n",
    "    # Create and fit encoder\n",
    "    encoders[feature] = LabelEncoder()\n",
    "    df_ml[f'{feature}_encoded'] = encoders[feature].fit_transform(df_ml[feature])\n",
    "    \n",
    "    print(f\"   {feature}: {len(encoders[feature].classes_)} unique values\")\n",
    "\n",
    "# Select features for the model\n",
    "feature_columns = [\n",
    "    'offence_encoded', 'appeal_district_encoded', 'trial_district_encoded', 'sentence_encoded',\n",
    "    'no_complainant', 'no_male_complainant', 'no_female_complainant',\n",
    "    'no_appealant', 'no_male_appealant', 'no_female_appealant', \n",
    "    'no_public_witness', 'no_eye_witness', 'no_defense_witness'\n",
    "]\n",
    "\n",
    "# Prepare feature matrix and target\n",
    "X = df_ml[feature_columns]\n",
    "y = df_ml['scn_decision']\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {X.shape}\")\n",
    "print(f\"Target distribution: {y.value_counts().to_dict()}\")\n",
    "\n",
    "# =====================================================\n",
    "# SPLIT DATA AND TRAIN MODEL\n",
    "# =====================================================\n",
    "\n",
    "print(\"\\n2. TRAINING THE MODEL...\")\n",
    "\n",
    "# Split data (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} cases\")\n",
    "print(f\"Test set: {len(X_test)} cases\")\n",
    "\n",
    "# Train Random Forest model\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "# =====================================================\n",
    "# EVALUATE MODEL PERFORMANCE\n",
    "# =====================================================\n",
    "\n",
    "print(\"\\n3. MODEL PERFORMANCE:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Overall Accuracy: {accuracy:.3f} ({accuracy*100:.1f}%)\")\n",
    "\n",
    "# Show detailed classification report\n",
    "print(\"\\nDetailed Performance:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(\"                Predicted\")\n",
    "print(\"                Dismissed  Granted\")\n",
    "print(f\"Actual Dismissed    {cm[0,0]:>6}    {cm[0,1]:>6}\")\n",
    "print(f\"Actual Granted      {cm[1,0]:>6}    {cm[1,1]:>6}\")\n",
    "\n",
    "# =====================================================\n",
    "# FEATURE IMPORTANCE ANALYSIS\n",
    "# =====================================================\n",
    "\n",
    "print(\"\\n4. MOST IMPORTANT FACTORS:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Map encoded features back to readable names\n",
    "feature_mapping = {\n",
    "    'offence_encoded': 'Offense Type',\n",
    "    'appeal_district_encoded': 'Appeal Region', \n",
    "    'trial_district_encoded': 'Trial Region',\n",
    "    'sentence_encoded': 'Original Sentence',\n",
    "    'no_eye_witness': 'Number of Eye Witnesses',\n",
    "    'no_public_witness': 'Number of Public Witnesses',\n",
    "    'no_defense_witness': 'Number of Defense Witnesses',\n",
    "    'no_complainant': 'Number of Complainants',\n",
    "    'no_appealant': 'Number of Appellants'\n",
    "}\n",
    "\n",
    "print(\"Factor                          | Importance Score\")\n",
    "print(\"-\" * 50)\n",
    "for _, row in feature_importance.head(8).iterrows():\n",
    "    readable_name = feature_mapping.get(row['feature'], row['feature'])\n",
    "    print(f\"{readable_name[:30]:<30} | {row['importance']:.3f}\")"
   ],
   "id": "8f6b49d1d65c02ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. PREPARING DATA FOR ML...\n",
      "   offence: 21 unique values\n",
      "   appeal_district: 7 unique values\n",
      "   trial_district: 8 unique values\n",
      "   sentence: 11 unique values\n",
      "\n",
      "Feature matrix shape: (1718, 13)\n",
      "Target distribution: {'Dismissed': 1211, 'Granted': 507}\n",
      "\n",
      "2. TRAINING THE MODEL...\n",
      "Training set: 1374 cases\n",
      "Test set: 344 cases\n",
      "\n",
      "3. MODEL PERFORMANCE:\n",
      "========================================\n",
      "Overall Accuracy: 0.698 (69.8%)\n",
      "\n",
      "Detailed Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Dismissed       0.71      0.98      0.82       242\n",
      "     Granted       0.38      0.03      0.05       102\n",
      "\n",
      "    accuracy                           0.70       344\n",
      "   macro avg       0.54      0.50      0.44       344\n",
      "weighted avg       0.61      0.70      0.59       344\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted\n",
      "                Dismissed  Granted\n",
      "Actual Dismissed       237         5\n",
      "Actual Granted          99         3\n",
      "\n",
      "4. MOST IMPORTANT FACTORS:\n",
      "========================================\n",
      "Factor                          | Importance Score\n",
      "--------------------------------------------------\n",
      "Offense Type                   | 0.183\n",
      "Original Sentence              | 0.151\n",
      "Trial Region                   | 0.120\n",
      "Appeal Region                  | 0.110\n",
      "Number of Appellants           | 0.094\n",
      "Number of Complainants         | 0.090\n",
      "no_male_appealant              | 0.073\n",
      "Number of Public Witnesses     | 0.071\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T12:35:10.398597Z",
     "start_time": "2025-08-10T12:35:10.353954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n5. TESTING WITH EXAMPLE CASES:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "def predict_case_outcome(case_details):\n",
    "    \"\"\"Predict outcome for a specific case\"\"\"\n",
    "    \n",
    "    # Create a single row dataframe\n",
    "    case_df = pd.DataFrame([case_details])\n",
    "    \n",
    "    # Encode categorical features\n",
    "    for feature in categorical_features:\n",
    "        if feature in case_df.columns:\n",
    "            case_df[feature] = case_df[feature].fillna('Unknown')\n",
    "            try:\n",
    "                case_df[f'{feature}_encoded'] = encoders[feature].transform(case_df[feature])\n",
    "            except ValueError:\n",
    "                # Handle unseen categories\n",
    "                case_df[f'{feature}_encoded'] = 0\n",
    "    \n",
    "    # Select features and predict\n",
    "    case_features = case_df[feature_columns].fillna(0)\n",
    "    prediction = model.predict(case_features)[0]\n",
    "    probability = model.predict_proba(case_features)[0]\n",
    "    \n",
    "    # Get confidence score\n",
    "    confidence = max(probability)\n",
    "    \n",
    "    return prediction, confidence\n",
    "\n",
    "# Test case 1: High-success case type\n",
    "print(\"\\nExample 1 - Trespassing case (should have higher success chance):\")\n",
    "test_case_1 = {\n",
    "    'offence': 'Trespassing',\n",
    "    'appeal_district': 'North-East',\n",
    "    'trial_district': 'North-East', \n",
    "    'sentence': 'Fine',\n",
    "    'no_complainant': 1,\n",
    "    'no_male_complainant': 1,\n",
    "    'no_female_complainant': 0,\n",
    "    'no_appealant': 1,\n",
    "    'no_male_appealant': 1,\n",
    "    'no_female_appealant': 0,\n",
    "    'no_public_witness': 2,\n",
    "    'no_eye_witness': 1,\n",
    "    'no_defense_witness': 2\n",
    "}\n",
    "\n",
    "prediction_1, confidence_1 = predict_case_outcome(test_case_1)\n",
    "print(f\"  Predicted: {prediction_1}\")\n",
    "print(f\"  Confidence: {confidence_1:.1%}\")\n",
    "\n",
    "# Test case 2: Low-success case type  \n",
    "print(\"\\nExample 2 - Armed robbery case (should have lower success chance):\")\n",
    "test_case_2 = {\n",
    "    'offence': 'Armed_robbery',\n",
    "    'appeal_district': 'FCT',\n",
    "    'trial_district': 'FCT',\n",
    "    'sentence': 'Death',\n",
    "    'no_complainant': 1,\n",
    "    'no_male_complainant': 1,\n",
    "    'no_female_complainant': 0,\n",
    "    'no_appealant': 1,\n",
    "    'no_male_appealant': 1, \n",
    "    'no_female_appealant': 0,\n",
    "    'no_public_witness': 3,\n",
    "    'no_eye_witness': 2,\n",
    "    'no_defense_witness': 0\n",
    "}\n",
    "\n",
    "prediction_2, confidence_2 = predict_case_outcome(test_case_2)\n",
    "print(f\"  Predicted: {prediction_2}\")\n",
    "print(f\"  Confidence: {confidence_2:.1%}\")"
   ],
   "id": "b6ebf1fd4c3eb77f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. TESTING WITH EXAMPLE CASES:\n",
      "========================================\n",
      "\n",
      "Example 1 - Trespassing case (should have higher success chance):\n",
      "  Predicted: Dismissed\n",
      "  Confidence: 77.2%\n",
      "\n",
      "Example 2 - Armed robbery case (should have lower success chance):\n",
      "  Predicted: Dismissed\n",
      "  Confidence: 68.4%\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T12:35:36.330500Z",
     "start_time": "2025-08-10T12:35:36.317655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model and encoders\n",
    "model_data = {\n",
    "    'model': model,\n",
    "    'encoders': encoders,\n",
    "    'feature_columns': feature_columns,\n",
    "    'feature_mapping': feature_mapping\n",
    "}\n",
    "\n",
    "with open('compulaw_ai_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model_data, f)\n",
    "\n",
    "print(f\"\\n✅ MODEL TRAINING COMPLETE!\")\n",
    "print(f\"✅ Model saved to 'compulaw_ai_model.pkl'\")\n",
    "print(f\"✅ Model accuracy: {accuracy:.1%}\")\n",
    "print(f\"✅ Ready for Step 4: Building the web interface!\")"
   ],
   "id": "241038af2575191d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ MODEL TRAINING COMPLETE!\n",
      "✅ Model saved to 'compulaw_ai_model.pkl'\n",
      "✅ Model accuracy: 69.8%\n",
      "✅ Ready for Step 4: Building the web interface!\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3f519d3bbdf097d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
